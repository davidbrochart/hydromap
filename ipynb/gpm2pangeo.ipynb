{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import xarray as xr\n",
    "import zarr\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import subprocess\n",
    "import h5py\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell bellow:\n",
    "- set `resume_upload=True` when resuming an upload (must be `False` for the first upload).\n",
    "- `dt0` is the initial date of the dataset and must remain constant between uploads.\n",
    "- `dt1` is the date up to which you want to upload (excluded), and has to be increased between uploads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt0 = datetime(2014, 3, 12) # DO NOT CHANGE (must stay constant between uploads)\n",
    "dt1 = datetime(2014, 3, 12, 4) # upload up to this date (excluded)\n",
    "resume_upload = True\n",
    "if resume_upload:\n",
    "    with open('tmp/dt1.pkl', 'rb') as f:\n",
    "        dt = pickle.load(f)\n",
    "else:\n",
    "    dt = dt0\n",
    "    shutil.rmtree('gpm_imerg_early', ignore_errors=True)\n",
    "    #gcloud init\n",
    "    #gcloud auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_nb = 4\n",
    "login = os.getenv('GPM_LOGIN')\n",
    "fields = ['precipitationCal',\n",
    "          'precipitationUncal',\n",
    "          'randomError',\n",
    "          'HQprecipitation',\n",
    "          'HQprecipSource',\n",
    "          'HQobservationTime',\n",
    "          'IRprecipitation',\n",
    "          'IRkalmanFilterWeight',\n",
    "          'probabilityLiquidPrecipitation',\n",
    "          'precipitationQualityIndex']\n",
    "shutil.rmtree('tmp/gpm_data', ignore_errors=True)\n",
    "shutil.rmtree('tmp/gpm_new', ignore_errors=True)\n",
    "os.makedirs('tmp/gpm_data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files(dt, date_nb):\n",
    "    datetimes = [dt + timedelta(minutes=30*i) for i in range(date_nb)]\n",
    "    urls, filenames = [], []\n",
    "    for t in datetimes:\n",
    "        year = t.year\n",
    "        month = str(t.month).zfill(2)\n",
    "        day = str(t.day).zfill(2)\n",
    "        hour = str(t.hour).zfill(2)\n",
    "        min0 = str(t.minute).zfill(2)\n",
    "        min1 = t.minute + 29\n",
    "        minutes = str(t.hour*60+t.minute).zfill(4)\n",
    "        filename = f'3B-HHR-E.MS.MRG.3IMERG.{year}{month}{day}-S{hour}{min0}00-E{hour}{min1}59.{minutes}.V05B.RT-H5'\n",
    "        urls.append(f'ftp://jsimpson.pps.eosdis.nasa.gov/NRTPUB/imerg/early/{year}{month}/{filename}')\n",
    "        filenames.append(filename)\n",
    "    with open('tmp/gpm_list.txt', 'w') as f:\n",
    "        f.write('\\n'.join(urls))\n",
    "    p = subprocess.Popen(f'aria2c -x {date_nb} -i tmp/gpm_list.txt -d tmp/gpm_data --ftp-user={login} --ftp-passwd={login} --continue=true'.split(), stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    return p, filenames, datetimes, dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_time = True\n",
    "while dt < dt1:\n",
    "    if first_time:\n",
    "        first_time = False\n",
    "        p, filenames, datetimes, download_from_dt = download_files(dt, date_nb)\n",
    "    new_time = [i + timedelta(minutes=15) for i in datetimes]\n",
    "    waiting = False\n",
    "    done = False\n",
    "    while not done:\n",
    "        return_code = p.poll()\n",
    "        if return_code is None:\n",
    "            if not waiting:\n",
    "                t0 = time.time()\n",
    "                waiting = True\n",
    "            time.sleep(0.2)\n",
    "        elif return_code != 0:\n",
    "            time.sleep(1800) # 30 minutes\n",
    "            p, _, _, _ = download_files(download_from_dt, date_nb)\n",
    "        else:\n",
    "            done = True\n",
    "    if waiting:\n",
    "        t1 = time.time()\n",
    "        print(f'Waited {round(t1-t0, 1)} seconds for download')\n",
    "    print('\\n'.join([str(i) for i in datetimes]))\n",
    "    ds = []\n",
    "    for fname in filenames:\n",
    "        try:\n",
    "            f = h5py.File(f'tmp/gpm_data/{fname}', 'r')\n",
    "            last_ds = xr.Dataset({field: (['lon', 'lat'], f[f'Grid/{field}']) for field in fields}, coords={'lon':f['Grid/lon'], 'lat':f['Grid/lat']}).transpose()\n",
    "            ds.append(last_ds)\n",
    "            f.close()\n",
    "        except:\n",
    "            ds.append(last_ds)\n",
    "    shutil.rmtree('tmp/gpm_data', ignore_errors=True)\n",
    "    os.makedirs('tmp/gpm_data', exist_ok=True)\n",
    "    next_dt = dt + timedelta(minutes=30*date_nb)\n",
    "    p, next_filenames, next_datetimes, download_from_dt = download_files(next_dt, date_nb)\n",
    "    ds = xr.concat(ds, 'time')\n",
    "    ds = ds.assign_coords(time=new_time)\n",
    "    if os.path.exists('gpm_imerg_early'):\n",
    "        ds.to_zarr('tmp/gpm_new')\n",
    "        for dname in [f for f in os.listdir('gpm_imerg_early') if not f.startswith('.')]:\n",
    "            for fname in [f for f in os.listdir(f'gpm_imerg_early/{dname}') if not f.startswith('.')]:\n",
    "                os.remove(f'gpm_imerg_early/{dname}/{fname}')\n",
    "        gpm = zarr.open('gpm_imerg_early', mode='a')\n",
    "        gpm_new = zarr.open('tmp/gpm_new', mode='r')\n",
    "        for key in [k for k in gpm.array_keys() if k not in ['lat', 'lon']]:\n",
    "            gpm[key].append(gpm_new[key])\n",
    "        gpm['time'][-date_nb:] = zarr.array([i - (dt0 + timedelta(minutes=15)) for i in new_time], dtype='m8[m]')\n",
    "        shutil.rmtree('tmp/gpm_new', ignore_errors=True)\n",
    "        subprocess.check_call('gsutil -m cp -r gpm_imerg_early/ gs://pangeo-data/'.split())\n",
    "        #subprocess.check_call('cp -r gpm_imerg_early/* gpm_bucket/', shell=True)\n",
    "    else:\n",
    "        ds.to_zarr('gpm_imerg_early')\n",
    "        subprocess.check_call('gsutil -m cp -r gpm_imerg_early/ gs://pangeo-data/'.split())\n",
    "        #subprocess.check_call('cp -r gpm_imerg_early/ gpm_bucket/'.split())\n",
    "    dt, filenames, datetimes = next_dt, next_filenames, next_datetimes\n",
    "with open('tmp/dt1.pkl', 'wb') as f:\n",
    "    pickle.dump(dt1, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
